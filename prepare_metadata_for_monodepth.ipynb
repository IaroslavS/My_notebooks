{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d5ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0f67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path_of_splits = '/home/cds-s/workspace/monodepth2/splits/eigen_full/'\n",
    "root_path_of_habitat_dataset = '/media/cds-s/data/Datasets/Habitat/extracted_HPointLoc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7a7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"index_to_image_filename\": {},\n",
    "    \"index_to_depth_filename\": {}\n",
    "}\n",
    "num_image = 0\n",
    "for num_map, map_name in enumerate(sorted(os.listdir(root_path_of_habitat_dataset))):\n",
    "    if map_name == \"1LXtFkjw3qL_point0\":\n",
    "        continue\n",
    "    image_filenames = list(Path(os.path.join(root_path_of_habitat_dataset, map_name)).glob('**/*.png'))\n",
    "    for image_filename in sorted(image_filenames):\n",
    "        image_filename = str(Path(image_filename).relative_to(Path(root_path_of_habitat_dataset)))\n",
    "        dataset[\"index_to_image_filename\"][num_image] = image_filename\n",
    "        depth_filename = image_filename.replace(\"images\", \"depth\")\n",
    "        dataset[\"index_to_depth_filename\"][num_image] = depth_filename\n",
    "        num_image += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c5f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/cds-s/data/Datasets/Habitat/extracted_HPointLoc/data.json', 'w') as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acde39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(os.path.join(root_path_of_splits, 'train_files.txt'), 'w')\n",
    "val_file = open(os.path.join(root_path_of_splits, 'val_files.txt'), 'w')\n",
    "test_map = '1LXtFkjw3qL_point0'\n",
    "for num_frame, image_filename in dataset[\"index_to_image_filename\"].items():\n",
    "    if image_filename.find(test_map) != -1:\n",
    "        continue\n",
    "    \n",
    "    if num_frame < 0.632 * len(dataset[\"index_to_image_filename\"].items()):\n",
    "        train_file.write(\"{0} {1}\\n\".format(image_filename, num_frame))\n",
    "    else:\n",
    "        val_file.write(\"{0} {1}\\n\".format(image_filename, num_frame))\n",
    "train_file.close()\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256e559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
